Project 1 â€” Linear Regression From Scratch

This project implements Linear Regression without sklearn, using only NumPy.
It builds strong intuition for how ML works under the hood.

ğŸ¯ Concepts Learned
âœ” Linear Regression Basics

Hypothesis function:
hÎ¸(x) = Î¸x + b

Meaning of theta (slope) and bias (intercept)

What a feature is and how X.shape determines data dimensions

âœ” Gradient Descent

Why gradient descent is needed

Parameter update rules:

Î¸ := Î¸ - Î± * dÎ¸
b := b - Î± * db


Role of learning rate

Meaning of iterations / epochs

âœ” Evaluation Metrics

MSE (Mean Squared Error)

RMSE

MAE

RÂ² Score

Inference Time

Cost Decreasing Plot (Loss Curve)

âœ” Synthetic Data Generation

Why synthetic data is useful for learning

What np.random.seed(42) means (reproducibility)

How noise affects learned parameters (bias shifting)

â“ Common Questions You Asked (and Understood)
1ï¸âƒ£ What is np.random.seed(42)?

Makes randomness repeatable

Ensures same synthetic data every run

Without it â†’ different results every time

2ï¸âƒ£ What is X.shape?

Shows dataset dimensions

Example: (100, 1) â†’ 100 samples, 1 feature

Needed for correct weight initialization

3ï¸âƒ£ Why do we add noise in synthetic data?

To simulate real-world imperfect data

Makes regression realistic

Explains why learned bias â‰  exactly true bias

4ï¸âƒ£ Why use y_pred = dot(X, theta) + bias?

This is the linear regression equation

First predictions are usually wrong â†’ gradient descent fixes them

5ï¸âƒ£ Why these gradients?
d_theta = (1/n) * np.dot(X.T, (y_pred - y))
d_bias  = (1/n) * np.sum(y_pred - y)


Because these are partial derivatives of MSE.
They show how to adjust Î¸ and b to reduce error.

6ï¸âƒ£ Why eval.py does NOT use train.py's trained model?

eval.py re-trains a new model using the same data

Thatâ€™s why results look similar

Later we will add:

model saving

model loading

inference script

7ï¸âƒ£ What is inference speed?

Time taken for prediction

Linear regression is extremely fast (microseconds)

ğŸ§ª Example Evaluation Output
--- Evaluation Metrics ---
MSE: 20.50
RMSE: 4.52
MAE: 3.57
RÂ²: 0.9895
Inference Time: 0.0000047 seconds


Interpretation:

Slope â‰ˆ 3.03

Bias â‰ˆ 8.42 (noise pulled it down)

RÂ² â‰ˆ 0.99 â†’ excellent fit

Very fast inference time

ğŸš€ How to Run the Project
Train Model
python train.py

Evaluate Model
python eval.py


Outputs:

Evaluation metrics

Cost (loss) curve

Learned regression line

ğŸ“‚ Project Folder Structure
project1_linear_regression_scratch/
â”‚â”€â”€ data.py               # synthetic dataset
â”‚â”€â”€ model.py              # scratch regression model
â”‚â”€â”€ train.py              # trains the model
â”‚â”€â”€ eval.py               # evaluates + plots
â”‚â”€â”€ README.md             # documentation

ğŸŒŸ Next Step: Project 2 â€” Linear Regression using sklearn

In the next project, we will:

Compare scratch model vs sklearn

Use real-world datasets

Measure performance differences

Validate correctness